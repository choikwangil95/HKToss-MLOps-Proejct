import streamlit as st
import pandas as pd
from streamlit_folium import st_folium
import folium
import toml
import joblib
import urllib
from data_preprocessing import pipeline
from folium import DivIcon
import os
from feature_preprocessing import DataScaler, DataEncoder, pipeline2
from data_preprocessing_base import pipeline_base
from data_preprocessing_online import pipeline_online
from data_preprocessing import pipeline


def get_kakao_api_key():
    # âœ… secrets.toml ë¡œë“œ (ë¡œì»¬ í™˜ê²½ë§Œ)
    kakao_api_key_by_toml = None
    if os.path.exists("../secrets.toml"):  # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°ë§Œ ë¡œë“œ
        try:
            secrets = toml.load("../secrets.toml")
            kakao_api_key_by_toml = secrets.get("general", {}).get("kakao_api_key")
        except Exception as e:
            print(f"âš ï¸ Warning: secrets.tomlì„ ë¡œë“œí•  ìˆ˜ ì—†`ë‹¤. ({e})")

    # âœ… ìµœì¢…ì ìœ¼ë¡œ í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸° (ìš°ì„ ìˆœìœ„: .env > secrets.toml > Streamlit Secrets)
    kakao_api_key = (
        kakao_api_key_by_toml or  # âœ… ë¡œì»¬: secrets.toml ì‚¬ìš©
        st.secrets.get("general", {}).get("kakao_api_key")  # âœ… Streamlit Cloud í™˜ê²½
    )

    return kakao_api_key


def print_estate_list(df_unique):
    df_unique_view = df_unique[['ê³µê¸‰ì§€ì—­ëª…' ,'ì£¼íƒëª…', 'ê³µê¸‰ê·œëª¨', 'ì²­ì•½ì ‘ìˆ˜ì‹œì‘ì¼', 'ì²­ì•½ì ‘ìˆ˜ì¢…ë£Œì¼', 'ë‹¹ì²¨ìë°œí‘œì¼']]

    st.dataframe(df_unique_view, use_container_width=True)


def print_estate_list_map(df_unique):
    df_unique_map = df_unique
    df_unique_map["ìœ„ë„"] = df_unique_map["ìœ„ë„"].astype(float)
    df_unique_map["ê²½ë„"] = df_unique_map["ê²½ë„"].astype(float)

    # ì§€ë„ ìƒì„± (ì„œìš¸ ì¤‘ì‹¬)
    center_lat = df_unique_map["ìœ„ë„"].astype(float).mean()
    center_lon = df_unique_map["ê²½ë„"].astype(float).mean()
    m = folium.Map(location=[center_lat, center_lon], zoom_start=12)

    # âœ… ëª¨ë“  ì¢Œí‘œì˜ ìµœì†Œ/ìµœëŒ€ê°’ì„ ì‚¬ìš©í•˜ì—¬ ê²½ê³„(Bounds) ê³„ì‚°
    bounds = [
        [df_unique["ìœ„ë„"].min(), df_unique["ê²½ë„"].min()], 
        [df_unique["ìœ„ë„"].max(), df_unique["ê²½ë„"].max()]
    ]

    # âœ… ì§€ë„ì— ëª¨ë“  ë§¤ë¬¼ì´ í¬í•¨ë˜ë„ë¡ ì„¤ì •
    m.fit_bounds(bounds)

    # ë§ˆì»¤ ì¶”ê°€
    for _, row in df_unique_map.iterrows():
        folium.Marker(
            location=[row["ìœ„ë„"], row["ê²½ë„"]],
            radius=10,  # ì›ì˜ í¬ê¸°
            color="red",  # ì› í…Œë‘ë¦¬ ìƒ‰ìƒ
            # popup=f"ì£¼íƒëª…: {row['ì£¼íƒëª…']}"  # íŒì—… ì •ë³´
        ).add_to(m)

        # ì› ìœ„ì— ì£¼íƒëª… ì¶”ê°€ (í•­ìƒ í‘œì‹œë¨)
        folium.map.Marker(
            [row["ìœ„ë„"] - 0.002, row["ê²½ë„"] - 0.025],
            icon=DivIcon(
                icon_size=(150, 36),
                icon_anchor=(0, 0),
                html=f'<div style="font-size: 12px; color: black; background: white; width: 150px; white-space: wrap; border: 1px solid black; padding: 3px; border-radius: 5px;">[{row["ê³µê¸‰ì§€ì—­ëª…"]}] {row["ì£¼íƒëª…"]}</div>'
            )
        ).add_to(m)

    # Streamlitì— ì§€ë„ í‘œì‹œ
    st_folium(m, width=700, height=500)


def predict_target(target, model, version, data):
    # âœ… ëª¨ë¸ ì €ì¥ ê²½ë¡œ
    model_url = f"https://raw.githubusercontent.com/choikwangil95/HKToss-MLOps-Proejct/streamlit/src/storage/trained_model/model_{target}_{model}_{version}.pkl"
    model_path = f"./storage/trained_model/model_{target}_{model}_{version}.pkl"

    # âœ… í´ë” í™•ì¸ ë° ìƒì„±
    if not os.path.exists("./storage/trained_model"):
        os.makedirs("./storage/trained_model")

    # âœ… GitHubì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    if not os.path.exists(model_path):
        print("ğŸ”½ ëª¨ë¸ì„ GitHubì—ì„œ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        urllib.request.urlretrieve(model_url, model_path)
        print("âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")

    # âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    trained_model = joblib.load(model_path)
    trained_model = joblib.load(f"./storage/trained_model/model_{target}_{model}_{version}.pkl")

    # âœ… Pipeline ê°ì²´ë¥¼ ìƒì„±í•  ë•Œ pipeline()ì„ í˜¸ì¶œí•´ì•¼ í•¨
    preprocessing_pipeline = pipeline(type='predict')

    # âœ… íŒŒì´í”„ë¼ì¸ ì €ì¥ ê²½ë¡œ
    pipeline_url = f"https://raw.githubusercontent.com/choikwangil95/HKToss-MLOps-Proejct/streamlit/src/storage/trained_pipeline/pipeline_{target}_{model}_{version}.pkl"
    pipeline_path = f"./storage/trained_pipeline/pipeline_{target}_{model}_{version}.pkl"

    # âœ… í´ë” í™•ì¸ ë° ìƒì„±
    if not os.path.exists("./storage/trained_pipeline"):
        os.makedirs("./storage/trained_pipeline")

    # âœ… GitHubì—ì„œ íŒŒì´í”„ë¼ì¸ ë‹¤ìš´ë¡œë“œ
    if not os.path.exists(pipeline_path):
        print("ğŸ”½ íŒŒì´í”„ë¼ì¸ì„ GitHubì—ì„œ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        urllib.request.urlretrieve(pipeline_url, pipeline_path)
        print("âœ… íŒŒì´í”„ë¼ì¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")

    # âœ… íŒŒì´í”„ë¼ì¸ ë¶ˆëŸ¬ì˜¤ê¸°
    feature_pipeline = joblib.load(pipeline_path)

    # âœ… DataEncoder ì†ì„± ì¬ì„¤ì • (í´ë¼ìš°ë“œ ì‹¤í–‰ ì‹œ í•„ìš”)
    if "encoder" in feature_pipeline.named_steps:
        encoder = feature_pipeline.named_steps["encoder"]
        encoder.encoder_url = f"https://raw.githubusercontent.com/choikwangil95/HKToss-MLOps-Proejct/streamlit/src/storage/trained_transformer/label_encoder_{target}_{model}_{version}.pkl"
        encoder.one_hot_url = f"https://raw.githubusercontent.com/choikwangil95/HKToss-MLOps-Proejct/streamlit/src/storage/trained_transformer/one_hot_columns_{target}_{model}_{version}.pkl"
        print("âœ… DataEncoderì˜ URL ì†ì„± ì¬ì„¤ì • ì™„ë£Œ!")

    # âœ… DataScaler ì†ì„± ì¬ì„¤ì •
    if "scaler" in feature_pipeline.named_steps:
        scaler = feature_pipeline.named_steps["scaler"]
        scaler.scaler_url = f"https://raw.githubusercontent.com/choikwangil95/HKToss-MLOps-Proejct/streamlit/src/storage/trained_transformer/{target}_{model}_scaler_powertransformer_{version}.pkl"
        scaler.scaler_path = f"./storage/trained_transformer/{target}_{model}_scaler_powertransformer_{version}.pkl"
        print("âœ… DataScalerì˜ URL ì†ì„± ì¬ì„¤ì • ì™„ë£Œ!")


    # âœ… ë³€í™˜ ì‹¤í–‰
    df_selected_house = preprocessing_pipeline.transform(data)
    df_selected_house = feature_pipeline.transform(df_selected_house)

    # ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼
    predicted = trained_model.predict(df_selected_house)

    return predicted