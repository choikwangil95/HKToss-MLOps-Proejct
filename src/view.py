import streamlit as st
import pandas as pd
from streamlit_folium import st_folium
import folium
import toml
import joblib
import urllib
from data_preprocessing import pipeline
from folium import DivIcon
import os
from feature_preprocessing import DataScaler, DataEncoder, pipeline2
from data_preprocessing_base import pipeline_base
from data_preprocessing_online import pipeline_online
from data_preprocessing import pipeline
import shap


def get_kakao_api_key():
    # âœ… secrets.toml ë¡œë“œ (ë¡œì»¬ í™˜ê²½ë§Œ)
    kakao_api_key_by_toml = None
    if os.path.exists("../secrets.toml"):  # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°ë§Œ ë¡œë“œ
        try:
            secrets = toml.load("../secrets.toml")
            kakao_api_key_by_toml = secrets.get("general", {}).get("kakao_api_key")
        except Exception as e:
            print(f"âš ï¸ Warning: secrets.tomlì„ ë¡œë“œí•  ìˆ˜ ì—†`ë‹¤. ({e})")

    # âœ… ìµœì¢…ì ìœ¼ë¡œ í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸° (ìš°ì„ ìˆœìœ„: .env > secrets.toml > Streamlit Secrets)
    kakao_api_key = (
        kakao_api_key_by_toml  # âœ… ë¡œì»¬: secrets.toml ì‚¬ìš©
        or st.secrets.get("general", {}).get("kakao_api_key")  # âœ… Streamlit Cloud í™˜ê²½
    )

    return kakao_api_key


def print_estate_list(df_unique):
    df_unique_view = df_unique[
        [
            "ê³µê¸‰ì§€ì—­ëª…",
            "ì£¼íƒëª…",
            "ê³µê¸‰ê·œëª¨",
            "ì²­ì•½ì ‘ìˆ˜ì‹œì‘ì¼",
            "ì²­ì•½ì ‘ìˆ˜ì¢…ë£Œì¼",
            "ë‹¹ì²¨ìë°œí‘œì¼",
        ]
    ]

    st.dataframe(df_unique_view, use_container_width=True)


def print_estate_list_map(df_unique):
    df_unique_map = df_unique
    df_unique_map["ìœ„ë„"] = df_unique_map["ìœ„ë„"].astype(float)
    df_unique_map["ê²½ë„"] = df_unique_map["ê²½ë„"].astype(float)

    # ì§€ë„ ìƒì„± (ì„œìš¸ ì¤‘ì‹¬)
    center_lat = df_unique_map["ìœ„ë„"].astype(float).mean()
    center_lon = df_unique_map["ê²½ë„"].astype(float).mean()
    m = folium.Map(
        location=[center_lat, center_lon],
        zoom_start=12,
        # dragging=False,  # ğŸ›‘ ë§ˆìš°ìŠ¤ë¡œ ë“œë˜ê·¸ ê¸ˆì§€
        # zoom_control=False,  # ğŸ” í”ŒëŸ¬ìŠ¤/ë§ˆì´ë„ˆìŠ¤ ë²„íŠ¼ ìˆ¨ê¹€
        scrollWheelZoom=False,  # ğŸ–±ï¸ ë§ˆìš°ìŠ¤ íœ ë¡œ í™•ëŒ€/ì¶•ì†Œ ë§‰ê¸°
        doubleClickZoom=False,  # â¬†ï¸ ë”ë¸”í´ë¦­ í™•ëŒ€ ê¸ˆì§€
        # touchZoom=False,  # ğŸ“± ëª¨ë°”ì¼ í•€ì¹˜ í™•ëŒ€ ê¸ˆì§€)
    )

    # âœ… ëª¨ë“  ì¢Œí‘œì˜ ìµœì†Œ/ìµœëŒ€ê°’ì„ ì‚¬ìš©í•˜ì—¬ ê²½ê³„(Bounds) ê³„ì‚°
    bounds = [
        [df_unique["ìœ„ë„"].min(), df_unique["ê²½ë„"].min()],
        [df_unique["ìœ„ë„"].max(), df_unique["ê²½ë„"].max()],
    ]

    # âœ… ì§€ë„ì— ëª¨ë“  ë§¤ë¬¼ì´ í¬í•¨ë˜ë„ë¡ ì„¤ì •
    m.fit_bounds(bounds)

    # ì´ë¯¸ì§€ url ì¶”ê°€
    df_unique_map["img_url"] = [
        "https://byw.kr/wp-content/uploads/2022/12/about_img-1080x675.jpg",
        "https://buly.kr/DPTWoNI",
        "https://cdn.straightnews.co.kr/news/photo/202502/263223_168321_222.jpg",
        "https://s.zigbang.com/v2/web/og/zigbang_aerial.png",
    ]

    # ë§ˆì»¤ ì¶”ê°€
    # ë§ˆì»¤ + tooltip ì¶”ê°€
    for _, row in df_unique_map.iterrows():
        folium.Marker(
            location=[row["ìœ„ë„"], row["ê²½ë„"]],
            icon=folium.Icon(color="red", icon="home", prefix="fa"),
            popup=None,  # í´ë¦­ ë¹„í™œì„±í™”
            # tooltip=f"[{row['ê³µê¸‰ì§€ì—­ëª…']}] {row['ì£¼íƒëª…']}",
            tooltip=None,
            interactive=False,  # âœ… í´ë¦­ ì´ë²¤íŠ¸ ì™„ì „ ì°¨ë‹¨!
        ).add_to(m)

        # í…ìŠ¤íŠ¸ DivIcon (ì¤‘ì•™ í•˜ë‹¨ ìœ„ì¹˜)
        folium.map.Marker(
            location=[
                row["ìœ„ë„"],
                row["ê²½ë„"],
            ],  # ì•„ì´ì½˜ ë°”ë¡œ ì•„ë˜ì— ìœ„ì¹˜
            interactive=False,  # âœ… í´ë¦­ ì´ë²¤íŠ¸ ì™„ì „ ì°¨ë‹¨!
            icon=DivIcon(
                icon_size=(0, 0),  # ì‹¤ì œ ì•„ì´ì½˜ í¬ê¸°ëŠ” ì˜ë¯¸ ì—†ìŒ
                icon_anchor=(68, -10),  # ì¤‘ì•™ í•˜ë‹¨ ê¸°ì¤€ (í…ìŠ¤íŠ¸ ìƒì widthì˜ ì ˆë°˜)
                html=f"""
                    <div style="
                        pointer-events: none;  /* â—í´ë¦­ ë°©ì§€ */
                        font-size: 12px;
                        font-weight: 600;
                        color: black;
                        background-color: white;
                        padding: 4px 6px;
                        border: 1px solid #888;
                        border-radius: 4px;
                        box-shadow: 1px 1px 4px rgba(0,0,0,0.2);
                        text-align: center;
                        min-width: 150px;       /* âœ… ìµœì†Œ ë„ˆë¹„ ì„¤ì • */
                        max-width: 220px;
                        white-space: nowrap;    /* âœ… ì¤„ë°”ê¿ˆ ë°©ì§€ */
                        overflow: hidden;
                        text-overflow: ellipsis;
                    ">
                        [{row["ê³µê¸‰ì§€ì—­ëª…"]}] {row["ì£¼íƒëª…"]}
                    </div>
                """,
            ),
        ).add_to(m)

        # 2. í•­ìƒ ë…¸ì¶œë˜ëŠ” ì´ë¯¸ì§€ íˆ´íŒ (ë§ˆì»¤ ìœ„ì— ìœ„ì¹˜)
        folium.Marker(
            location=[
                row["ìœ„ë„"],
                row["ê²½ë„"],
            ],  # ë§ˆì»¤ë³´ë‹¤ ì•½ê°„ ìœ„ë¡œ ë„ìš°ê¸°
            interactive=False,  # âœ… í´ë¦­ ì´ë²¤íŠ¸ ì™„ì „ ì°¨ë‹¨!
            icon=DivIcon(
                icon_size=(20, 10),
                icon_anchor=(40, 100),
                html=f"""
                <div style="
                    pointer-events: none;  /* â—í´ë¦­ ë°©ì§€ */
                    background-color: white;
                    border: 1px solid #ccc;
                    border-radius: 5px;
                    box-shadow: 0 0 4px rgba(0,0,0,0.15);
                    padding: 3px;
                ">
                    <img src="{row['img_url']}" width="50" height="50" />
                </div>
                """,
            ),
        ).add_to(m)

    # ì§€ë„ ì¶œë ¥
    st_folium(m, width=700, height=500)


def predict_target(target, model, version, data):
    # âœ… ëª¨ë¸ ì €ì¥ ê²½ë¡œ
    model_url = f"https://raw.githubusercontent.com/choikwangil95/HKToss-MLOps-Proejct/streamlit/src/storage/trained_model/model_{target}_{model}_{version}.pkl"
    model_path = f"./storage/trained_model/model_{target}_{model}_{version}.pkl"

    # âœ… í´ë” í™•ì¸ ë° ìƒì„±
    if not os.path.exists("./storage/trained_model"):
        os.makedirs("./storage/trained_model")

    # âœ… GitHubì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    if not os.path.exists(model_path):
        print("ğŸ”½ ëª¨ë¸ì„ GitHubì—ì„œ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        urllib.request.urlretrieve(model_url, model_path)
        print("âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")

    # âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    trained_model = joblib.load(model_path)
    trained_model = joblib.load(
        f"./storage/trained_model/model_{target}_{model}_{version}.pkl"
    )

    # âœ… Pipeline ê°ì²´ë¥¼ ìƒì„±í•  ë•Œ pipeline()ì„ í˜¸ì¶œí•´ì•¼ í•¨
    preprocessing_pipeline = pipeline(type="predict", target=target)

    # âœ… íŒŒì´í”„ë¼ì¸ ì €ì¥ ê²½ë¡œ
    pipeline_url = f"https://raw.githubusercontent.com/choikwangil95/HKToss-MLOps-Proejct/streamlit/src/storage/trained_pipeline/pipeline_{target}_{model}_{version}.pkl"
    pipeline_path = (
        f"./storage/trained_pipeline/pipeline_{target}_{model}_{version}.pkl"
    )

    # âœ… í´ë” í™•ì¸ ë° ìƒì„±
    if not os.path.exists("./storage/trained_pipeline"):
        os.makedirs("./storage/trained_pipeline")

    # âœ… GitHubì—ì„œ íŒŒì´í”„ë¼ì¸ ë‹¤ìš´ë¡œë“œ
    if not os.path.exists(pipeline_path):
        print("ğŸ”½ íŒŒì´í”„ë¼ì¸ì„ GitHubì—ì„œ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        urllib.request.urlretrieve(pipeline_url, pipeline_path)
        print("âœ… íŒŒì´í”„ë¼ì¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")

    # âœ… íŒŒì´í”„ë¼ì¸ ë¶ˆëŸ¬ì˜¤ê¸°
    feature_pipeline = joblib.load(pipeline_path)

    if not os.path.exists("./storage/trained_transformer"):
        os.makedirs("./storage/trained_transformer")

    # âœ… DataEncoder ì†ì„± ì¬ì„¤ì • (í´ë¼ìš°ë“œ ì‹¤í–‰ ì‹œ í•„ìš”)
    if "encoder" in feature_pipeline.named_steps:
        encoder = feature_pipeline.named_steps["encoder"]
        encoder.encoder_url = f"https://raw.githubusercontent.com/choikwangil95/HKToss-MLOps-Proejct/streamlit/src/storage/trained_transformer/{target}_{model}_label_encoder_{version}.pkl"
        encoder.one_hot_url = f"https://raw.githubusercontent.com/choikwangil95/HKToss-MLOps-Proejct/streamlit/src/storage/trained_transformer/{target}_{model}_one_hot_columns_{version}.pkl"
        print("âœ… DataEncoderì˜ URL ì†ì„± ì¬ì„¤ì • ì™„ë£Œ!")

    # âœ… DataScaler ì†ì„± ì¬ì„¤ì •
    if "scaler" in feature_pipeline.named_steps:
        scaler = feature_pipeline.named_steps["scaler"]
        scaler.scaler_url = f"https://raw.githubusercontent.com/choikwangil95/HKToss-MLOps-Proejct/streamlit/src/storage/trained_transformer/{target}_{model}_scaler_powertransformer_{version}.pkl"
        print("âœ… DataScalerì˜ URL ì†ì„± ì¬ì„¤ì • ì™„ë£Œ!")

    # âœ… ë³€í™˜ ì‹¤í–‰
    df_selected_house = preprocessing_pipeline.transform(data)
    df_selected_house = feature_pipeline.transform(df_selected_house)

    test = df_selected_house["íˆ¬ê¸°ê³¼ì—´ì§€êµ¬_N"]

    print(f"debug {test}==========================================================")

    # ì—­ë³€í™˜ìš© ë°ì´í„° ë³µì‚¬
    df_selected_house_reversed = df_selected_house.copy()

    # feature_pipeline ë‚´ ìŠ¤í… ì—­ìˆœìœ¼ë¡œ ìˆœíšŒ
    for step_name, step in reversed(feature_pipeline.steps):
        if hasattr(step, "inverse_transform"):
            df_selected_house_reversed = step.inverse_transform(
                df_selected_house_reversed
            )

    # ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼
    predicted = trained_model.predict(df_selected_house)

    explainer = shap.TreeExplainer(trained_model)
    shap_values = explainer.shap_values(df_selected_house)
    expected_value = explainer.expected_value

    return predicted, df_selected_house_reversed, shap_values, expected_value
