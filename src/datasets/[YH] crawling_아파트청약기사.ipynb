{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### '아파트 청약'기사 크롤링 함수\n",
    "- 내용에 '아파트 청약' 키워드가 포함된 기사 크롤링\n",
    "    - 기간: 2020~2024\n",
    "    - 합계: 91개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_news_url(apartment_name: str) -> str:\n",
    "    \"\"\"아파트 청약 키워드 검색 URL 생성\"\"\"\n",
    "    base_url = \"https://search.naver.com/search.naver\"\n",
    "    query = 'query'\n",
    "    \n",
    "    params = {\n",
    "        \"where\": \"news\",\n",
    "        \"query\": query,\n",
    "        \"sm\": \"tab_opt\",\n",
    "        \"sort\": \"1\"  # 최신순 정렬\n",
    "    }\n",
    "    \n",
    "    return base_url + \"?\" + urllib.parse.urlencode(params, quote_via=urllib.parse.quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아파트 청약 관련 뉴스 크롤링 시작...\n",
      "\n",
      "===== 2020년 크롤링 시작 =====\n",
      "2020년에는 더 이상 기사가 없습니다.\n",
      "2020년 크롤링 완료: 4개의 기사 수집\n",
      "\n",
      "===== 2021년 크롤링 시작 =====\n",
      "2021년에는 더 이상 기사가 없습니다.\n",
      "2021년 크롤링 완료: 6개의 기사 수집\n",
      "\n",
      "===== 2022년 크롤링 시작 =====\n",
      "2022년에는 더 이상 기사가 없습니다.\n",
      "2022년 크롤링 완료: 11개의 기사 수집\n",
      "\n",
      "===== 2023년 크롤링 시작 =====\n",
      "2023년에는 더 이상 기사가 없습니다.\n",
      "2023년 크롤링 완료: 56개의 기사 수집\n",
      "\n",
      "===== 2024년 크롤링 시작 =====\n",
      "2024년에는 더 이상 기사가 없습니다.\n",
      "2024년 크롤링 완료: 14개의 기사 수집\n",
      "\n",
      "총 91개의 기사가 수집되었습니다.\n",
      "크롤링 결과가 '2020_2024_아파트청약_뉴스_연도별_크롤링.csv' 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import urllib.parse\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def generate_news_url(query: str, start: int, start_date: str, end_date: str) -> str:\n",
    "    \"\"\"네이버 뉴스 검색 URL 생성\"\"\"\n",
    "    base_url = \"https://search.naver.com/search.naver\"\n",
    "    params = {\n",
    "        \"where\": \"news\",\n",
    "        \"query\": query,\n",
    "        \"sm\": \"tab_opt\",\n",
    "        \"sort\": \"1\",  # 최신순 정렬\n",
    "        \"start\": start,  # 페이지 시작 번호 (1, 11, 21...)\n",
    "        \"nso\": f\"so:dd,p:from{start_date}to{end_date},a:all\"  # 날짜 범위 필터\n",
    "    }\n",
    "    return base_url + \"?\" + urllib.parse.urlencode(params, quote_via=urllib.parse.quote)\n",
    "\n",
    "def crawl_naver_news(query: str, year: int, max_articles_per_year: int = 100) -> list:\n",
    "    \"\"\"네이버 뉴스에서 특정 키워드와 연도별 기사 크롤링\"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    articles = []\n",
    "    start = 1  # 네이버 뉴스 검색 결과의 첫 번째 페이지부터 시작\n",
    "    start_date = f\"{year}0101\"  # 검색 시작 날짜 (YYYYMMDD)\n",
    "    end_date = f\"{year}1231\"  # 검색 종료 날짜 (YYYYMMDD)\n",
    "\n",
    "    while len(articles) < max_articles_per_year:\n",
    "        try:\n",
    "            # 검색 URL 생성\n",
    "            search_url = generate_news_url(query, start, start_date, end_date)\n",
    "            response = requests.get(search_url, headers=headers)\n",
    "            response.raise_for_status()  # HTTP 오류 발생 시 예외 발생\n",
    "\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # 네이버 뉴스 링크 필터링 (네이버 뉴스만)\n",
    "            news_links = [\n",
    "                a['href'] for a in soup.select('a.info')\n",
    "                if '네이버뉴스' in a.text and 'news.naver.com' in a['href']\n",
    "            ]\n",
    "\n",
    "            if not news_links:  # 더 이상 기사가 없으면 종료\n",
    "                print(f\"{year}년에는 더 이상 기사가 없습니다.\")\n",
    "                break\n",
    "\n",
    "            for article_url in news_links:\n",
    "                if len(articles) >= max_articles_per_year:\n",
    "                    break\n",
    "\n",
    "                try:\n",
    "                    # 개별 기사 페이지 요청\n",
    "                    article_res = requests.get(article_url, headers=headers, timeout=5)\n",
    "                    article_res.raise_for_status()\n",
    "                    article_soup = BeautifulSoup(article_res.text, 'html.parser')\n",
    "\n",
    "                    # 본문 추출\n",
    "                    content_elem = article_soup.select_one('#newsct_article, #dic_area')\n",
    "                    if content_elem:\n",
    "                        content = content_elem.get_text(strip=True)\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                    # 키워드 필터링 (\"아파트 청약\" 포함 여부 확인)\n",
    "                    if \"아파트 청약\" not in content:\n",
    "                        continue\n",
    "\n",
    "                    # 제목 및 날짜 추출\n",
    "                    title_elem = article_soup.select_one('#title_area')\n",
    "                    date_elem = article_soup.select_one('.media_end_head_info_datestamp_time')\n",
    "\n",
    "                    if title_elem and date_elem:\n",
    "                        articles.append({\n",
    "                            \"title\": title_elem.get_text(strip=True),\n",
    "                            \"date\": date_elem['data-date-time'],\n",
    "                            \"content\": content,\n",
    "                            \"url\": article_url,\n",
    "                            \"year\": year\n",
    "                        })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"기사 처리 실패 ({article_url}): {str(e)}\")\n",
    "\n",
    "            start += 10  # 다음 페이지로 이동\n",
    "            time.sleep(2)  # 요청 간 대기 시간 설정\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"페이지 처리 실패 ({search_url}): {str(e)}\")\n",
    "            break\n",
    "\n",
    "    return articles\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"아파트 청약\"\n",
    "\n",
    "    print(f\"{query} 관련 뉴스 크롤링 시작...\")\n",
    "\n",
    "    all_news_data = []\n",
    "\n",
    "    for year in range(2020, 2025):  # 2020년부터 2024년까지 반복\n",
    "        print(f\"\\n===== {year}년 크롤링 시작 =====\")\n",
    "        yearly_news_data = crawl_naver_news(query, year, max_articles_per_year=100)\n",
    "        all_news_data.extend(yearly_news_data)\n",
    "        print(f\"{year}년 크롤링 완료: {len(yearly_news_data)}개의 기사 수집\")\n",
    "\n",
    "    print(f\"\\n총 {len(all_news_data)}개의 기사가 수집되었습니다.\")\n",
    "\n",
    "    # 결과 출력 및 저장\n",
    "    df = pd.DataFrame(all_news_data)\n",
    "    df.to_csv('2020_2024_아파트청약_뉴스_연도별_크롤링.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"크롤링 결과가 '2020_2024_아파트청약_뉴스_연도별_크롤링.csv' 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>부산, 올해 2만 5817가구 분양…강서·동래·부산진구에 집중</td>\n",
       "      <td>2020-12-31 19:08:43</td>\n",
       "      <td>부산 동래구 온천2구역 주택재개발정비사업 현장. 부산일보DB2021년 전국 민간 아...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/082/000...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[생생경제]청약, 기존 재고주택으로 분산 필요... 결국 집값 안정 전제되어야</td>\n",
       "      <td>2020-12-31 17:47:03</td>\n",
       "      <td>■ 방송 : YTN 라디오 FM 94.5 (15:10~16:00)■ 날짜 : 202...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/052/000...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"올해도 상한제 '로또 분양' 계속\"</td>\n",
       "      <td>2020-12-31 16:29:06</td>\n",
       "      <td>건설사 분양시장 전망3기신도시에 수요 일부 분산\"재건축 규제 풀어 공급 늘려야\"주요...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/015/000...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>주거용 오피스텔 찾는 실수요층...구리 갈매지구 ‘힐스테이트 갈매역 스칸센’ 관심</td>\n",
       "      <td>2020-12-31 14:24:21</td>\n",
       "      <td>[아이뉴스24 이도영 기자] 최근 대출과 세금, 청약 규제 등으로 아파트 진입장벽이...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/031/000...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"메타버스부터 CCTV까지\"…2022 랜선 해돋이 명소는?</td>\n",
       "      <td>2021-12-31 19:00:00</td>\n",
       "      <td>유튜브 채팅창에 \"로또 1등\" \"다이어트 성공\" 기도지도앱 CCTV로 보는 새해 일...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/421/000...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title                 date  \\\n",
       "0             부산, 올해 2만 5817가구 분양…강서·동래·부산진구에 집중  2020-12-31 19:08:43   \n",
       "1    [생생경제]청약, 기존 재고주택으로 분산 필요... 결국 집값 안정 전제되어야  2020-12-31 17:47:03   \n",
       "2                           \"올해도 상한제 '로또 분양' 계속\"  2020-12-31 16:29:06   \n",
       "3  주거용 오피스텔 찾는 실수요층...구리 갈매지구 ‘힐스테이트 갈매역 스칸센’ 관심  2020-12-31 14:24:21   \n",
       "4               \"메타버스부터 CCTV까지\"…2022 랜선 해돋이 명소는?  2021-12-31 19:00:00   \n",
       "\n",
       "                                             content  \\\n",
       "0  부산 동래구 온천2구역 주택재개발정비사업 현장. 부산일보DB2021년 전국 민간 아...   \n",
       "1  ■ 방송 : YTN 라디오 FM 94.5 (15:10~16:00)■ 날짜 : 202...   \n",
       "2  건설사 분양시장 전망3기신도시에 수요 일부 분산\"재건축 규제 풀어 공급 늘려야\"주요...   \n",
       "3  [아이뉴스24 이도영 기자] 최근 대출과 세금, 청약 규제 등으로 아파트 진입장벽이...   \n",
       "4  유튜브 채팅창에 \"로또 1등\" \"다이어트 성공\" 기도지도앱 CCTV로 보는 새해 일...   \n",
       "\n",
       "                                                 url  year  \n",
       "0  https://n.news.naver.com/mnews/article/082/000...  2020  \n",
       "1  https://n.news.naver.com/mnews/article/052/000...  2020  \n",
       "2  https://n.news.naver.com/mnews/article/015/000...  2020  \n",
       "3  https://n.news.naver.com/mnews/article/031/000...  2020  \n",
       "4  https://n.news.naver.com/mnews/article/421/000...  2021  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('2020_2024_아파트청약_뉴스_연도별_크롤링.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yeeun_Han",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
