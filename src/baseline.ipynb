{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 23,
         "metadata": {},
         "outputs": [],
         "source": [
            "import pandas as pd\n",
            "import numpy as np\n",
            "\n",
            "from sklearn.ensemble import RandomForestRegressor\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.metrics import mean_squared_error, r2_score\n",
            "\n",
            "import joblib\n",
            "\n",
            "from data_preprocessing import pipeline, filter_unnecessary_columns\n",
            "from feature_preprocessing import pipeline2\n",
            "\n",
            "import matplotlib.pyplot as plt\n",
            "plt.rcParams['font.family'] ='Malgun Gothic'\n",
            "plt.rcParams['axes.unicode_minus'] =False"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 데이터 전처리"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 24,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26212\\584858293.py:3: DtypeWarning: Columns (48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df = pd.read_csv(file_path)\n",
                  "c:\\Users\\user\\mid_project\\src\\data_preprocessing.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
                  "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
                  "\n",
                  "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
                  "\n",
                  "\n",
                  "  df['최고당첨가점'].fillna(0, inplace=True)\n",
                  "c:\\Users\\user\\mid_project\\src\\data_preprocessing.py:80: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
                  "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
                  "\n",
                  "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
                  "\n",
                  "\n",
                  "  df['최저당첨가점'].fillna(0, inplace=True)\n",
                  "c:\\Users\\user\\mid_project\\src\\data_preprocessing.py:81: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
                  "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
                  "\n",
                  "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
                  "\n",
                  "\n",
                  "  df['평균당첨가점'].fillna(0, inplace=True)\n",
                  "c:\\Users\\user\\mid_project\\src\\data_preprocessing.py:163: DtypeWarning: Columns (36,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                  "  df_estate_price = pd.read_csv(csv_path, encoding=\"cp949\")\n"
               ]
            }
         ],
         "source": [
            "# 로우 데이터 불러오기\n",
            "file_path = \"./storage/raw_data/병합_청약매물_목록_정보_픽스2.csv\"\n",
            "df = pd.read_csv(file_path)\n",
            "\n",
            "# 데이터 전처리\n",
            "preprocessing_pipeline = pipeline(type='train')\n",
            "df = preprocessing_pipeline.transform(df)\n",
            "\n",
            "# 학습할 모델별로 드랍할 칼럼 정의\n",
            "# - 최고당첨가점: 공급지역코드, 거래금액(만원), 공급세대수\n",
            "# 최저당첨가점: 공급지역코드, 거래금액(만원), 공급세대수\n",
            "# 시세차익: 공급지역코드, 공급세대수\n",
            "\n",
            "#  -----------------------------최고, 최저당점가점용-----------------------------------\n",
            "df['시세차익'] = df['전용면적'] * df['전용면적당 시세차익']\n",
            "df.drop(columns=['전용면적', '전용면적당 시세차익', '공급금액(최고가 기준)'], inplace=True)\n",
            "# 최고, 최저당점가점용\n",
            "df.drop(['공급지역코드', '거래금액(만원)', '공급세대수'], axis=1, inplace=True)\n",
            "\n",
            "\n",
            "#  -----------------------------시세차익용-----------------------------------\n",
            "# 시세차익 할 때 feature에서 거래금액(만원) 이부분 스케일링 해주기\n",
            "# df['시세차익'] = df['전용면적'] * df['전용면적당 시세차익']\n",
            "# df.drop(columns=['전용면적', '전용면적당 시세차익', '공급금액(최고가 기준)'], inplace=True)\n",
            "# df.drop(['공급지역코드', '공급세대수'], axis=1, inplace=True)\n",
            "\n",
            "\n",
            "# 파일 저장\n",
            "file_version = \"250320-당첨가점\"\n",
            "output_file = f\"./storage/train_data/train-{file_version}.csv\"\n",
            "df.to_csv(output_file, index=False, encoding='cp949')"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 모델 학습 및 평가"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 25,
         "metadata": {},
         "outputs": [],
         "source": [
            "# 전처리된 데이터 가져오기\n",
            "\n",
            "file_path = f\"./storage/train_data/train-{file_version}.csv\"\n",
            "df = pd.read_csv(file_path, encoding='cp949')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "X = df.drop(columns=[\"최고당첨가점\"])\n",
            "Y = df[\"최고당첨가점\"]\n",
            "\n",
            "X_train, X_test, y_train, y_test = train_test_split(\n",
            "    X,  # 타겟\n",
            "    Y,  \n",
            "    test_size=0.2,\n",
            "    random_state=42\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Index(['공급지역코드', '공급규모', '투기과열지구', '조정대상지역', '분양가상한제', '정비사업', '공공주택지구',\n",
                  "       '대규모택지개발지구', '수도권내민영공공주택지구', '공급세대수', '순위', '거주지역', '접수건수', '경쟁률',\n",
                  "       '토픽 1', '토픽 2', '토픽 3', '토픽 4', '토픽 5', '토픽 6', '토픽 7', '법정동코드'],\n",
                  "      dtype='object')\n",
                  "Index(['공급규모', '공급세대수', '접수건수', '경쟁률', '토픽 1', '토픽 2', '토픽 3', '토픽 4', '토픽 5',\n",
                  "       '토픽 6', '토픽 7', '법정동코드', '투기과열지구_N', '투기과열지구_Y', '조정대상지역_N', '조정대상지역_Y',\n",
                  "       '분양가상한제_N', '분양가상한제_Y', '정비사업_N', '정비사업_Y', '공공주택지구_N', '공공주택지구_Y',\n",
                  "       '대규모택지개발지구_N', '대규모택지개발지구_Y', '거주지역_기타경기', '거주지역_기타지역', '거주지역_해당지역',\n",
                  "       '공급지역코드_100', '공급지역코드_400', '공급지역코드_410', '수도권내민영공공주택지구_N',\n",
                  "       '수도권내민영공공주택지구_Y', '순위_1순위', '순위_2순위'],\n",
                  "      dtype='object')\n",
                  "Index(['공급지역코드', '공급규모', '투기과열지구', '조정대상지역', '분양가상한제', '정비사업', '공공주택지구',\n",
                  "       '대규모택지개발지구', '수도권내민영공공주택지구', '공급세대수', '순위', '거주지역', '접수건수', '경쟁률',\n",
                  "       '토픽 1', '토픽 2', '토픽 3', '토픽 4', '토픽 5', '토픽 6', '토픽 7', '법정동코드'],\n",
                  "      dtype='object')\n",
                  "Index(['공급규모', '공급세대수', '접수건수', '경쟁률', '토픽 1', '토픽 2', '토픽 3', '토픽 4', '토픽 5',\n",
                  "       '토픽 6', '토픽 7', '법정동코드', '투기과열지구_N', '투기과열지구_Y', '조정대상지역_N', '조정대상지역_Y',\n",
                  "       '분양가상한제_N', '분양가상한제_Y', '정비사업_N', '정비사업_Y', '공공주택지구_N', '공공주택지구_Y',\n",
                  "       '대규모택지개발지구_N', '대규모택지개발지구_Y', '거주지역_기타경기', '거주지역_기타지역', '거주지역_해당지역',\n",
                  "       '공급지역코드_100', '공급지역코드_400', '공급지역코드_410', '수도권내민영공공주택지구_N',\n",
                  "       '수도권내민영공공주택지구_Y', '순위_1순위', '순위_2순위'],\n",
                  "      dtype='object')\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "c:\\Users\\user\\anaconda3\\envs\\project-env\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
                  "  warnings.warn(\n",
                  "c:\\Users\\user\\anaconda3\\envs\\project-env\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
                  "  warnings.warn(\n"
               ]
            }
         ],
         "source": [
            "feature_pipeline = pipeline2()\n",
            "\n",
            "# 학습 데이터(X_train)에 fit\n",
            "feature_pipeline.fit(X_train)\n",
            "\n",
            "# 학습 데이터(X_train)를 변환\n",
            "X_train_transformed = feature_pipeline.transform(X_train)\n",
            "\n",
            "# 테스트 데이터(X_test)를 변환\n",
            "X_test_transformed = feature_pipeline.transform(X_test)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [],
         "source": [
            "# shap test data 저장\n",
            "\n",
            "X_test_transformed.to_csv('./storage/shap_test_data/X_test_transformed.csv', index=False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "['./storage/trained_pipeline/pipeline_0.0.1.pkl']"
                  ]
               },
               "execution_count": 7,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# 피쳐 파이프라인 저장 \n",
            "\n",
            "version = '0.0.1'\n",
            "joblib.dump(feature_pipeline, f\"./storage/trained_pipeline/pipeline_{version}.pkl\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 학습 - LightGBM"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "'\\nRandomforest, XGB, LGB 비교결과\\nXGB가 가장 높았지만, 성능평가에서 0.1정도의 아주 작은 차이라 더 가볍고 빠르게 돌아가는 모델인 LightGBM 이용 제안\\n추후 결정되면 코드 적어놓겠음\\n'"
                  ]
               },
               "execution_count": 1,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "import lightgbm as lgb\n",
            "from sklearn.model_selection import RandomizedSearchCV\n",
            "from sklearn.metrics import mean_squared_error, r2_score\n",
            "import numpy as np\n",
            "import warnings\n",
            "\n",
            "# 워닝 무시\n",
            "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
            "\n",
            "lgb_model = lgb.LGBMRegressor(verbosity=-1)\n",
            "\n",
            "lgb_param_grid = {\n",
            "    'max_depth': np.arange(3, 9),  \n",
            "    'num_leaves': np.arange(31, 127),  \n",
            "    'min_data_in_leaf': np.arange(10, 50),  \n",
            "    'subsample': np.linspace(0.5, 1.0, 6),  \n",
            "    'colsample_bytree': np.linspace(0.5, 1.0, 6),  \n",
            "    'learning_rate': np.logspace(-4, -1, 10),  \n",
            "    'n_estimators': np.arange(50, 200, 50)  \n",
            "}\n",
            "\n",
            "# 랜덤 서치\n",
            "lgb_random_search = RandomizedSearchCV(\n",
            "    lgb_model, \n",
            "    param_distributions=lgb_param_grid, \n",
            "    cv=5, \n",
            "    n_iter=100,\n",
            ")\n",
            "\n",
            "lgb_random_search.fit(X_train_transformed, y_train)\n",
            "\n",
            "print(\"베스트 파라미터:\")\n",
            "print(lgb_random_search.best_params_)\n",
            "\n",
            "y_pred = lgb_random_search.best_estimator_.predict(X_test_transformed)\n",
            "\n",
            "# RMSE , R² \n",
            "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
            "r2 = r2_score(y_test, y_pred)\n",
            "\n",
            "print(f\"LightGBM - RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "특정 파라미터 값 결정 시 아래 코드 이용"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# import numpy as np\n",
            "# import matplotlib.pyplot as plt\n",
            "# import lightgbm as lgb\n",
            "# from sklearn.metrics import mean_squared_error, r2_score\n",
            "\n",
            "# lgb_model = lgb.LGBMRegressor(\n",
            "#     max_depth=8, \n",
            "#     num_leaves=119, \n",
            "#     min_data_in_leaf=47, \n",
            "#     subsample=0.7, \n",
            "#     colsample_bytree=0.9, \n",
            "#     learning_rate=0.1, \n",
            "#     n_estimators=100\n",
            "# )\n",
            "\n",
            "# lgb_model.fit(X_train_transformed, y_train)\n",
            "\n",
            "# y_pred_lgb = lgb_model.predict(X_test_transformed)\n",
            "\n",
            "# # RMSE , R^2\n",
            "# def evaluate_model(y_true, y_pred):\n",
            "#     rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
            "#     r2 = r2_score(y_true, y_pred)\n",
            "#     return rmse, r2\n",
            "\n",
            "# rmse_lgb, r2_lgb = evaluate_model(y_test, y_pred_lgb)\n",
            "# print(f\"LightGBM - RMSE: {rmse_lgb}, R^2: {r2_lgb}\")\n",
            "\n",
            "# feature_importances = lgb_model.feature_importances_\n",
            "\n",
            "# # Feature Importance\n",
            "# sorted_idx = np.argsort(feature_importances)[::-1]\n",
            "\n",
            "# plt.barh(X_train_transformed.columns[sorted_idx], feature_importances[sorted_idx])\n",
            "# plt.xlabel(\"Feature Importance\")\n",
            "# plt.ylabel(\"Feature Name\")\n",
            "# plt.show()\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 모델 저장 "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "['./storage/trained_model/model_rf_grid_0.0.1.pkl']"
                  ]
               },
               "execution_count": 10,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# 모델 저장 및 로드\n",
            "\n",
            "version = 'rf_grid_0.0.1'\n",
            "\n",
            "# 모델 저장\n",
            "joblib.dump(rf_model, f\"./storage/trained_model/model_{version}.pkl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [],
         "source": [
            "# 모델 로드\n",
            "loaded_model = joblib.load(\"./storage/trained_model/model_0.0.1.pkl\")\n",
            "\n",
            "# 예측\n",
            "# X_test = np.array([[1, 2]])\n",
            "# prediction = loaded_model.predict(X_test)\n",
            "# print(\"Prediction:\", prediction)"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "project-env",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.11"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
